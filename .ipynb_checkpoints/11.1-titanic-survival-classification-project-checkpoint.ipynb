{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/18 15:24:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/05/18 15:24:13 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark regression example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "df = spark.read.format('csv').options(header='true', inferschema='true').\\\n",
    "load('data/project/classification/titanic/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5> Show statistics of each column, including feature columns and label column (medv)  </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>891</td>\n",
       "      <td>446.0</td>\n",
       "      <td>257.3538420152301</td>\n",
       "      <td>1</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>891</td>\n",
       "      <td>0.3838383838383838</td>\n",
       "      <td>0.48659245426485753</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>891</td>\n",
       "      <td>2.308641975308642</td>\n",
       "      <td>0.8360712409770491</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>891</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>\"Andersson, Mr. August Edvard (\"\"Wennerstrom\"\")\"</td>\n",
       "      <td>van Melkebeke, Mr. Philemon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>891</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>female</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>714</td>\n",
       "      <td>29.69911764705882</td>\n",
       "      <td>14.526497332334035</td>\n",
       "      <td>0.42</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>891</td>\n",
       "      <td>0.5230078563411896</td>\n",
       "      <td>1.1027434322934315</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>891</td>\n",
       "      <td>0.38159371492704824</td>\n",
       "      <td>0.8060572211299488</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket</th>\n",
       "      <td>891</td>\n",
       "      <td>260318.54916792738</td>\n",
       "      <td>471609.26868834975</td>\n",
       "      <td>110152</td>\n",
       "      <td>WE/P 5735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>891</td>\n",
       "      <td>32.2042079685746</td>\n",
       "      <td>49.69342859718089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>204</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>A10</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>889</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0                    1                    2  \\\n",
       "summary      count                 mean               stddev   \n",
       "PassengerId    891                446.0    257.3538420152301   \n",
       "Survived       891   0.3838383838383838  0.48659245426485753   \n",
       "Pclass         891    2.308641975308642   0.8360712409770491   \n",
       "Name           891                 None                 None   \n",
       "Sex            891                 None                 None   \n",
       "Age            714    29.69911764705882   14.526497332334035   \n",
       "SibSp          891   0.5230078563411896   1.1027434322934315   \n",
       "Parch          891  0.38159371492704824   0.8060572211299488   \n",
       "Ticket         891   260318.54916792738   471609.26868834975   \n",
       "Fare           891     32.2042079685746    49.69342859718089   \n",
       "Cabin          204                 None                 None   \n",
       "Embarked       889                 None                 None   \n",
       "\n",
       "                                                            3  \\\n",
       "summary                                                   min   \n",
       "PassengerId                                                 1   \n",
       "Survived                                                    0   \n",
       "Pclass                                                      1   \n",
       "Name         \"Andersson, Mr. August Edvard (\"\"Wennerstrom\"\")\"   \n",
       "Sex                                                    female   \n",
       "Age                                                      0.42   \n",
       "SibSp                                                       0   \n",
       "Parch                                                       0   \n",
       "Ticket                                                 110152   \n",
       "Fare                                                      0.0   \n",
       "Cabin                                                     A10   \n",
       "Embarked                                                    C   \n",
       "\n",
       "                                       4  \n",
       "summary                              max  \n",
       "PassengerId                          891  \n",
       "Survived                               1  \n",
       "Pclass                                 3  \n",
       "Name         van Melkebeke, Mr. Philemon  \n",
       "Sex                                 male  \n",
       "Age                                 80.0  \n",
       "SibSp                                  8  \n",
       "Parch                                  6  \n",
       "Ticket                         WE/P 5735  \n",
       "Fare                            512.3292  \n",
       "Cabin                                  T  \n",
       "Embarked                               S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcols=[]\n",
    "for i in df.dtypes:\n",
    "    if i[1] == 'string':\n",
    "        catcols.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols=[]\n",
    "for i in df.dtypes:\n",
    "    if i[1] !='string' and i[0] != 'Survived':\n",
    "        num_cols.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelCol='Survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# categorical columns\n",
    "categorical_columns = catcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexers = [ StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c)) for c in categorical_columns ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(), \\\n",
    "                           outputCol=\"{0}_encoded\".format(indexer.getOutputCol())) for indexer in indexers ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[encoder.getOutputCol() \\\n",
    "                                       for encoder in encoders] + num_cols, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------+-----+\n",
      "|features                                                                                   |label|\n",
      "+-------------------------------------------------------------------------------------------+-----+\n",
      "|(449,[56,299,401,442,443,444,445,446,448],[1.0,1.0,1.0,1.0,2.0,1.0,38.0,1.0,71.2833])      |1    |\n",
      "|(449,[74,197,326,441,443,444,445,446,448],[1.0,1.0,1.0,1.0,4.0,1.0,35.0,1.0,53.1])         |1    |\n",
      "|(449,[115,182,264,433,441,443,444,445,448],[1.0,1.0,1.0,1.0,1.0,7.0,1.0,54.0,51.8625])     |0    |\n",
      "|(449,[149,223,311,441,443,444,445,446,447,448],[1.0,1.0,1.0,1.0,11.0,3.0,4.0,1.0,1.0,16.7])|1    |\n",
      "|(449,[35,245,381,441,443,444,445,448],[1.0,1.0,1.0,1.0,12.0,1.0,58.0,26.55])               |1    |\n",
      "+-------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
    "model=pipeline.fit(df)\n",
    "data = model.transform(df)\n",
    "data = data.withColumn('label',col(labelCol))\n",
    "data=data.select('features','label')\n",
    "data.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorIndexer\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous. \n",
    "# Update metadata accordingly.\n",
    "featureIndexer =VectorIndexer(inputCol=\"features\", \\\n",
    "                                  outputCol=\"indexedFeatures\", \\\n",
    "                                  maxCategories=4).fit(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|            features|label|     indexedFeatures|\n",
      "+--------------------+-----+--------------------+\n",
      "|(449,[56,299,401,...|    1|(449,[56,299,401,...|\n",
      "|(449,[74,197,326,...|    1|(449,[74,197,326,...|\n",
      "|(449,[115,182,264...|    0|(449,[115,182,264...|\n",
      "|(449,[149,223,311...|    1|(449,[149,223,311...|\n",
      "|(449,[35,245,381,...|    1|(449,[35,245,381,...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=featureIndexer.transform(data)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------+-----+----------------------------------------------------------------------------------------------+\n",
      "|features                                                                                      |label|indexedFeatures                                                                               |\n",
      "+----------------------------------------------------------------------------------------------+-----+----------------------------------------------------------------------------------------------+\n",
      "|(449,[0,272,315,441,443,444,445,448],[1.0,1.0,1.0,1.0,346.0,2.0,24.0,13.0])                   |1    |(449,[0,272,315,441,443,444,445,448],[1.0,1.0,1.0,1.0,346.0,1.0,24.0,13.0])                   |\n",
      "|(449,[1,252,350,442,443,444,445,446,448],[1.0,1.0,1.0,1.0,557.0,1.0,48.0,1.0,39.6])           |1    |(449,[1,252,350,442,443,444,445,446,448],[1.0,1.0,1.0,1.0,557.0,0.0,48.0,1.0,39.6])           |\n",
      "|(449,[2,182,215,351,442,443,444,445,446,448],[1.0,1.0,1.0,1.0,1.0,600.0,1.0,49.0,1.0,56.9292])|1    |(449,[2,182,215,351,442,443,444,445,446,448],[1.0,1.0,1.0,1.0,1.0,600.0,0.0,49.0,1.0,56.9292])|\n",
      "|(449,[4,293,404,442,443,444,445,448],[1.0,1.0,1.0,1.0,711.0,1.0,24.0,49.5042])                |1    |(449,[4,293,404,442,443,444,445,448],[1.0,1.0,1.0,1.0,711.0,0.0,24.0,49.5042])                |\n",
      "|(449,[5,182,190,314,441,443,444,445,447,448],[1.0,1.0,1.0,1.0,1.0,149.0,2.0,36.5,2.0,26.0])   |0    |(449,[5,182,190,314,441,443,444,445,447,448],[1.0,1.0,1.0,1.0,1.0,149.0,1.0,36.5,2.0,26.0])   |\n",
      "+----------------------------------------------------------------------------------------------+-----+----------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------------------------------------------------------------------------------------------------+-----+-----------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                             |label|indexedFeatures                                                                                      |\n",
      "+-----------------------------------------------------------------------------------------------------+-----+-----------------------------------------------------------------------------------------------------+\n",
      "|(449,[3,182,290,343,441,443,444,445,448],[1.0,1.0,1.0,1.0,1.0,573.0,1.0,36.0,26.3875])               |1    |(449,[3,182,290,343,441,443,444,445,448],[1.0,1.0,1.0,1.0,1.0,573.0,0.0,36.0,26.3875])               |\n",
      "|(449,[8,191,321,441,443,444,445,448],[1.0,1.0,1.0,1.0,731.0,1.0,29.0,211.3375])                      |1    |(449,[8,191,321,441,443,444,445,448],[1.0,1.0,1.0,1.0,731.0,0.0,29.0,211.3375])                      |\n",
      "|(449,[9,182,187,312,441,443,444,445,446,447,448],[1.0,1.0,1.0,1.0,1.0,306.0,1.0,0.92,1.0,2.0,151.55])|1    |(449,[9,182,187,312,441,443,444,445,446,447,448],[1.0,1.0,1.0,1.0,1.0,306.0,0.0,0.92,1.0,2.0,151.55])|\n",
      "|(449,[10,187,312,441,443,444,445,446,447,448],[1.0,1.0,1.0,1.0,298.0,1.0,2.0,1.0,2.0,151.55])        |0    |(449,[10,187,312,441,443,444,445,446,447,448],[1.0,1.0,1.0,1.0,298.0,0.0,2.0,1.0,2.0,151.55])        |\n",
      "|(449,[11,187,312,441,443,444,445,446,447,448],[1.0,1.0,1.0,1.0,499.0,1.0,25.0,1.0,2.0,151.55])       |0    |(449,[11,187,312,441,443,444,445,446,447,448],[1.0,1.0,1.0,1.0,499.0,0.0,25.0,1.0,2.0,151.55])       |\n",
      "+-----------------------------------------------------------------------------------------------------+-----+-----------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets (40% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.6, 0.4])\n",
    "trainingData.show(5,False)\n",
    "testData.show(5,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>\n",
    "\n",
    "Let's do Naive Baynes first\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "naivebayes = NaiveBayes(featuresCol=\"indexedFeatures\", labelCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model=naivebayes.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>\n",
    "\n",
    "Test the model with testData\n",
    "\n",
    "  \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|label|     indexedFeatures|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|    1|(449,[3,182,290,3...|\n",
      "|       1.0|    1|(449,[8,191,321,4...|\n",
      "|       1.0|    1|(449,[9,182,187,3...|\n",
      "|       1.0|    0|(449,[10,187,312,...|\n",
      "|       1.0|    0|(449,[11,187,312,...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_predictions = nb_model.transform(testData)\n",
    "nb_predictions.select(\"prediction\",\"label\",\"indexedFeatures\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7\n",
      "Test Error = 0.3\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(nb_predictions)\n",
    "print(f\"Accuracy = {accuracy}\")\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data (f1): 0.7012557832121613 \n",
      " training data (weightedPrecision):  0.7027972027972028 \n",
      " training data (weightedRecall):  0.7 \n",
      " training data (accuracy):  0.7\n"
     ]
    }
   ],
   "source": [
    "print('training data (f1):', evaluator.setMetricName('f1').evaluate(nb_predictions), \"\\n\",\n",
    "     'training data (weightedPrecision): ', evaluator.setMetricName('weightedPrecision').evaluate(nb_predictions),\"\\n\",\n",
    "     'training data (weightedRecall): ', evaluator.setMetricName('weightedRecall').evaluate(nb_predictions),\"\\n\",\n",
    "     'training data (accuracy): ', evaluator.setMetricName('accuracy').evaluate(nb_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>\n",
    "\n",
    "Let's do Logistic Regression\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "logr = LogisticRegression(featuresCol='indexedFeatures', labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/18 15:39:56 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/05/18 15:39:56 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "23/05/18 15:39:56 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "23/05/18 15:39:56 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"
     ]
    }
   ],
   "source": [
    "lg_model=logr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|label|     indexedFeatures|\n",
      "+----------+-----+--------------------+\n",
      "|       1.0|    1|(449,[3,182,290,3...|\n",
      "|       1.0|    1|(449,[8,191,321,4...|\n",
      "|       1.0|    1|(449,[9,182,187,3...|\n",
      "|       1.0|    0|(449,[10,187,312,...|\n",
      "|       1.0|    0|(449,[11,187,312,...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lg_predictions = lg_model.transform(testData)\n",
    "lg_predictions.select(\"prediction\",\"label\",\"indexedFeatures\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.5857142857142857\n",
      "Test Error = 0.414286\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(lg_predictions)\n",
    "print(f\"Accuracy = {accuracy}\")\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>\n",
    "\n",
    "Let's do Decision Tree\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(featuresCol='indexedFeatures', labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model=dt.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|label|     indexedFeatures|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|    1|(449,[3,182,290,3...|\n",
      "|       1.0|    1|(449,[8,191,321,4...|\n",
      "|       1.0|    1|(449,[9,182,187,3...|\n",
      "|       1.0|    0|(449,[10,187,312,...|\n",
      "|       1.0|    0|(449,[11,187,312,...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_predictions=dt_model.transform(testData)\n",
    "dt_predictions.select(\"prediction\",\"label\",\"indexedFeatures\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.5857142857142857\n",
      "Test Error = 0.414286\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(lg_predictions)\n",
    "print(f\"Accuracy = {accuracy}\")\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>\n",
    "\n",
    "Let's do Linear Support Vector Machine\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "lsvc = LinearSVC(featuresCol=\"indexedFeatures\", labelCol=\"label\", maxIter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model=lsvc.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|label|     indexedFeatures|\n",
      "+----------+-----+--------------------+\n",
      "|       1.0|    1|(449,[3,182,290,3...|\n",
      "|       1.0|    1|(449,[8,191,321,4...|\n",
      "|       1.0|    1|(449,[9,182,187,3...|\n",
      "|       1.0|    0|(449,[10,187,312,...|\n",
      "|       1.0|    0|(449,[11,187,312,...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_predictions=svc_model.transform(testData)\n",
    "svc_predictions.select(\"prediction\",\"label\",\"indexedFeatures\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7428571428571429\n",
      "Test Error = 0.257143\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(svc_predictions)\n",
    "print(f\"Accuracy = {accuracy}\")\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>\n",
    "\n",
    "Let's do Random Forest\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(featuresCol='indexedFeatures', labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model=rf.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|label|     indexedFeatures|\n",
      "+----------+-----+--------------------+\n",
      "|       1.0|    1|(449,[3,182,290,3...|\n",
      "|       1.0|    1|(449,[8,191,321,4...|\n",
      "|       1.0|    1|(449,[9,182,187,3...|\n",
      "|       1.0|    0|(449,[10,187,312,...|\n",
      "|       1.0|    0|(449,[11,187,312,...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_predictions=rf_model.transform(testData)\n",
    "rf_predictions.select(\"prediction\",\"label\",\"indexedFeatures\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6428571428571429\n",
      "Test Error = 0.357143\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(rf_predictions)\n",
    "print(f\"Accuracy = {accuracy}\")\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>\n",
    "\n",
    "Let's do Gradient Boosted Tree\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "gbt = GBTClassifier(featuresCol='indexedFeatures', labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_model=gbt.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|label|     indexedFeatures|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|    1|(449,[3,182,290,3...|\n",
      "|       1.0|    1|(449,[8,191,321,4...|\n",
      "|       1.0|    1|(449,[9,182,187,3...|\n",
      "|       1.0|    0|(449,[10,187,312,...|\n",
      "|       1.0|    0|(449,[11,187,312,...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbt_predictions=gbt_model.transform(testData)\n",
    "gbt_predictions.select(\"prediction\",\"label\",\"indexedFeatures\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8142857142857143\n",
      "Test Error = 0.185714\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(gbt_predictions)\n",
    "print(f\"Accuracy = {accuracy}\")\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>\n",
    "\n",
    "This concludes the testing of Spark ML Classifier\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
