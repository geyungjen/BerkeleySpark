{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create entry points to spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/02 17:46:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(master = 'local')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "          .appName(\"Python Spark SQL basic example\") \\\n",
    "          .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "          .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression without cross-valiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---------+-----+\n",
      "|   TV|Radio|Newspaper|Sales|\n",
      "+-----+-----+---------+-----+\n",
      "|230.1| 37.8|     69.2| 22.1|\n",
      "| 44.5| 39.3|     45.1| 10.4|\n",
      "| 17.2| 45.9|     69.3|  9.3|\n",
      "|151.5| 41.3|     58.5| 18.5|\n",
      "|180.8| 10.8|     58.4| 12.9|\n",
      "+-----+-----+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ad = spark.read.csv('data/Advertising.csv', header=True, inferSchema=True)\n",
    "ad.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data structure\n",
    "\n",
    "This is alternative to VectorAssembler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|         features|label|\n",
      "+-----------------+-----+\n",
      "|[230.1,37.8,69.2]| 22.1|\n",
      "| [44.5,39.3,45.1]| 10.4|\n",
      "| [17.2,45.9,69.3]|  9.3|\n",
      "|[151.5,41.3,58.5]| 18.5|\n",
      "|[180.8,10.8,58.4]| 12.9|\n",
      "+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "ad_df = ad.rdd.map(lambda x: [Vectors.dense(x[0:3]), x[-1]]).toDF(['features', 'label'])\n",
    "#To visualize, need to make features one dimension, use first column only\n",
    "#ad_df = ad.rdd.map(lambda x: [Vectors.dense(x[0:1]), x[-1]]).toDF(['features', 'label'])\n",
    "ad_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x=[] \n",
    "#y=[]\n",
    "#for i in ad_df.select(\"features\").collect():\n",
    "#    x.append(i[0][0])\n",
    "\n",
    "#for i in ad_df.select(\"label\").collect():\n",
    "#    y.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize = (10, 8))\n",
    "#plt.scatter(x, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol = 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 5:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/02 17:46:56 WARN Instrumentation: [b7093648] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/02 17:46:57 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/05/02 17:46:57 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "23/05/02 17:46:57 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lr_model = lr.fit(ad_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+------------------+\n",
      "|         features|label|        prediction|\n",
      "+-----------------+-----+------------------+\n",
      "|[230.1,37.8,69.2]| 22.1| 20.52397440971517|\n",
      "| [44.5,39.3,45.1]| 10.4|12.337854820894362|\n",
      "| [17.2,45.9,69.3]|  9.3|12.307670779994238|\n",
      "|[151.5,41.3,58.5]| 18.5| 17.59782951168913|\n",
      "|[180.8,10.8,58.4]| 12.9|13.188671856831299|\n",
      "+-----------------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = lr_model.transform(ad_df)\n",
    "pred.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.897210638178952"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator \n",
    "evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='label')\n",
    "evaluator.setMetricName('r2').evaluate(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression with cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = ad_df.randomSplit([0.8, 0.2], seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build cross-validation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##=====build cross valiation model======\n",
    "\n",
    "# estimator\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol = 'label')\n",
    "\n",
    "# parameter grid\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "param_grid = ParamGridBuilder().\\\n",
    "    addGrid(lr.regParam, [0, 0.5, 1]).\\\n",
    "    addGrid(lr.elasticNetParam, [0, 0.5, 1]).\\\n",
    "    build()\n",
    "    \n",
    "# evaluator\n",
    "evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='label', metricName='r2')\n",
    "\n",
    "# cross-validation model\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit cross-validation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/02 17:47:53 WARN Instrumentation: [b1fc64bb] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/02 17:47:54 WARN Instrumentation: [398cf2ce] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/02 17:47:54 WARN Instrumentation: [078938e9] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/02 17:47:56 WARN Instrumentation: [d57d1278] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/02 17:47:57 WARN Instrumentation: [f4657757] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/02 17:47:57 WARN Instrumentation: [ec862b9c] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/02 17:47:58 WARN Instrumentation: [458f73d9] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/02 17:47:59 WARN Instrumentation: [612b80a4] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/02 17:47:59 WARN Instrumentation: [ef8a5afe] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/02 17:48:00 WARN Instrumentation: [a612fb7d] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/02 17:48:01 WARN Instrumentation: [548b8cb4] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/02 17:48:01 WARN Instrumentation: [456404e1] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/02 17:48:02 WARN Instrumentation: [54f1d4bd] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    }
   ],
   "source": [
    "cv_model = cv.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_training_cv = cv_model.transform(training)\n",
    "pred_test_cv = cv_model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8952845631627804"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performance on training data\n",
    "evaluator.setMetricName('r2').evaluate(pred_training_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9013819610158471"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performance on test data\n",
    "evaluator.setMetricName('r2').evaluate(pred_test_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intercept and coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:  2.9592600706772934 \n",
      " coefficients:  [0.046137295249098154,0.19200356629524304,-0.006269704193266607]\n"
     ]
    }
   ],
   "source": [
    "print('Intercept: ', cv_model.bestModel.intercept, \"\\n\",\n",
    "     'coefficients: ', cv_model.bestModel.coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get parameter values from the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters can be extracted by calling the java property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best regParam: 0.0\n",
      "best ElasticNetParam:0.0\n"
     ]
    }
   ],
   "source": [
    "print('best regParam: ' + str(cv_model.bestModel._java_obj.getRegParam()) + \"\\n\" +\n",
    "     'best ElasticNetParam:' + str(cv_model.bestModel._java_obj.getElasticNetParam()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred=[]\n",
    "#for i in x:\n",
    "#    y_pred.append(cv_model.bestModel.coefficients[0]*i+cv_model.bestModel.intercept)\n",
    "\n",
    "#plt.figure(figsize = (10, 8))\n",
    "#plt.scatter(x, y);\n",
    "#plt.plot(x, y_pred,'r-');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
