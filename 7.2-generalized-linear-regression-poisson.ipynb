{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_samples, n_features = 1000, 20\n",
    "rng = np.random.RandomState(0)\n",
    "X = rng.randn(n_samples, n_features)\n",
    "#positive integer target correlated with X[:, 5] with many zeros:\n",
    "y = rng.poisson(lam=np.exp(X[:, 5]) / 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/03 00:22:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/05/03 00:22:49 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(master = 'local')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "          .appName(\"Python Spark SQL basic example\") \\\n",
    "          .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "          .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/usr/local/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import List\n",
    "from pyspark.ml.linalg import Vectors\n",
    "import pandas as pd\n",
    "x=[]\n",
    "for i in X:\n",
    "    x.append([int(u) for u in i])\n",
    "\n",
    "frame={'features':list(x),'label':list(y)}\n",
    "df=pd.DataFrame(frame)\n",
    "#df\n",
    "cuse=spark.createDataFrame(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[1, 0, 0, 2, 1, 0...|    0|\n",
      "|[-2, 0, 0, 0, 2, ...|    1|\n",
      "|[-1, -1, -1, 1, 0...|    1|\n",
      "|[0, 0, 0, -1, 0, ...|    0|\n",
      "|[-1, 0, 0, -1, 1,...|    5|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cuse.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 14:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cuse=cuse.rdd.map(lambda x: [Vectors.dense(x[0]), x[-1]]).toDF([\"features\", \"label\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[1.0,0.0,0.0,2.0,...|    0|\n",
      "|[-2.0,0.0,0.0,0.0...|    1|\n",
      "|[-1.0,-1.0,-1.0,1...|    1|\n",
      "|[0.0,0.0,0.0,-1.0...|    0|\n",
      "|[-1.0,0.0,0.0,-1....|    5|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 15:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# assemble all feature columns into on single vector column\n",
    "#from pyspark.ml.feature import VectorAssembler\n",
    "#assembler = VectorAssembler(inputCols=['x'], outputCol='features')\n",
    "#cuse_df_2 = assembler.transform(cuse).withColumnRenamed('y', 'label')\n",
    "cuse_df_2=cuse\n",
    "cuse_df_2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 16:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[-2.0,-3.0,0.0,0....|    2|\n",
      "|[-2.0,-1.0,0.0,-1...|    1|\n",
      "|[-2.0,0.0,-1.0,0....|   13|\n",
      "|[-2.0,0.0,-1.0,0....|    0|\n",
      "|[-2.0,0.0,0.0,-2....|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split data into training and test datasets\n",
    "training, test = cuse_df_2.randomSplit([0.8, 0.2], seed=1234)\n",
    "training.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ======= build cross validation model ===========\n",
    "\n",
    "# estimator\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "glm = GeneralizedLinearRegression(featuresCol='features', labelCol='label', family='poisson')\n",
    "\n",
    "# parameter grid\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "param_grid = ParamGridBuilder().\\\n",
    "    addGrid(glm.regParam, [0, 0.5, 1, 2, 4]).\\\n",
    "    build()\n",
    "    \n",
    "# evaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator \n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction')\n",
    "\n",
    "# build cross-validation model\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "cv = CrossValidator(estimator=glm, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/03 01:06:15 WARN Instrumentation: [a2c166b6] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:15 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/05/03 01:06:15 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "23/05/03 01:06:15 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "23/05/03 01:06:15 WARN Instrumentation: [a2c166b6] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:15 WARN Instrumentation: [a2c166b6] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:15 WARN Instrumentation: [a2c166b6] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:15 WARN Instrumentation: [a2c166b6] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:15 WARN Instrumentation: [a2c166b6] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:19 WARN Instrumentation: [dac4f1ee] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:19 WARN Instrumentation: [dac4f1ee] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:19 WARN Instrumentation: [dac4f1ee] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:19 WARN Instrumentation: [dac4f1ee] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:19 WARN Instrumentation: [dac4f1ee] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:19 WARN Instrumentation: [dac4f1ee] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:19 WARN Instrumentation: [dac4f1ee] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:21 WARN Instrumentation: [5a32b84d] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:21 WARN Instrumentation: [5a32b84d] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:21 WARN Instrumentation: [5a32b84d] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:21 WARN Instrumentation: [5a32b84d] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:21 WARN Instrumentation: [5a32b84d] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:21 WARN Instrumentation: [5a32b84d] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:23 WARN Instrumentation: [535887a9] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:23 WARN Instrumentation: [535887a9] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:23 WARN Instrumentation: [535887a9] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:23 WARN Instrumentation: [535887a9] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:23 WARN Instrumentation: [535887a9] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:23 WARN Instrumentation: [535887a9] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:25 WARN Instrumentation: [afcee937] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/03 01:06:26 WARN Instrumentation: [afcee937] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:27 WARN Instrumentation: [afcee937] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:27 WARN Instrumentation: [afcee937] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:27 WARN Instrumentation: [afcee937] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:06:27 WARN Instrumentation: [afcee937] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "# cv_model = cv.fit(training)\n",
    "cv_model = cv.fit(cuse_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------------+\n",
      "|            features|label|         prediction|\n",
      "+--------------------+-----+-------------------+\n",
      "|[-2.0,-3.0,0.0,0....|    2| 0.6799783168326854|\n",
      "|[-2.0,-1.0,0.0,-1...|    1|0.20613253412349647|\n",
      "|[-2.0,0.0,-1.0,0....|   13| 17.088318492592062|\n",
      "|[-2.0,0.0,-1.0,0....|    0| 0.9544955495061405|\n",
      "|[-2.0,0.0,0.0,-2....|    0| 0.6906118251089284|\n",
      "+--------------------+-----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------------------------------------------------------------------------------------+-----+-------------------+\n",
      "|features                                                                                |label|prediction         |\n",
      "+----------------------------------------------------------------------------------------+-----+-------------------+\n",
      "|[-2.0,-2.0,-1.0,0.0,0.0,-1.0,-1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]  |0    |0.22640640294783052|\n",
      "|[-2.0,0.0,-1.0,0.0,1.0,0.0,1.0,0.0,-1.0,0.0,0.0,0.0,1.0,0.0,-2.0,0.0,0.0,0.0,0.0,0.0]   |0    |0.7924349039987659 |\n",
      "|[-1.0,-1.0,-1.0,1.0,0.0,0.0,-1.0,0.0,-1.0,0.0,0.0,0.0,0.0,-1.0,0.0,0.0,0.0,0.0,0.0,0.0] |1    |0.6137107249108705 |\n",
      "|[-1.0,-1.0,0.0,0.0,-1.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0]    |0    |1.65331679706424   |\n",
      "|[-1.0,-1.0,0.0,0.0,0.0,0.0,-1.0,1.0,0.0,1.0,0.0,-2.0,0.0,-1.0,0.0,0.0,0.0,0.0,-1.0,-1.0]|1    |0.622204724728022  |\n",
      "+----------------------------------------------------------------------------------------+-----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "pred_training_cv = cv_model.transform(training)\n",
    "pred_test_cv = cv_model.transform(test)\n",
    "\n",
    "pred_training_cv.show(5)\n",
    "pred_test_cv.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-0.0333, -0.0172, -0.0027, 0.0413, 0.1633, 1.1194, 0.0018, -0.1042, 0.0884, 0.0095, 0.0135, -0.0576, 0.0144, 0.0103, -0.0445, 0.0739, -0.1006, 0.0887, 0.0694, -0.0183])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.bestModel.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.48223726493156294"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.bestModel.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv_model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7428980724709977"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(pred_training_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7321568627450977"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(pred_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ======= build cross validation model ===========\n",
    "\n",
    "# estimator\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "glm = GeneralizedLinearRegression(featuresCol='features', labelCol='label', family='tweedie')\n",
    "\n",
    "# parameter grid\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "param_grid = ParamGridBuilder().\\\n",
    "    addGrid(glm.regParam, [0, 0.5, 1, 2, 4]).\\\n",
    "    build()\n",
    "    \n",
    "# evaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction')\n",
    "\n",
    "# build cross-validation model\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "cv = CrossValidator(estimator=glm, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/03 01:08:37 WARN CacheManager: Asked to cache already cached data.\n",
      "23/05/03 01:08:37 WARN CacheManager: Asked to cache already cached data.\n",
      "23/05/03 01:08:37 WARN Instrumentation: [28d1b270] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/03 01:08:39 WARN Instrumentation: [02b4d443] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:08:41 WARN Instrumentation: [f9c6e7e7] regParam is zero, which might cause numerical instability and overfitting.\n",
      "23/05/03 01:08:42 WARN Instrumentation: [acb3cde1] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 628:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "# cv_model = cv.fit(training)\n",
    "cv_model = cv.fit(cuse_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------------+\n",
      "|            features|label|        prediction|\n",
      "+--------------------+-----+------------------+\n",
      "|[-2.0,-3.0,0.0,0....|    2|0.9179379646400883|\n",
      "|[-2.0,-1.0,0.0,-1...|    1|0.6069072619487946|\n",
      "|[-2.0,0.0,-1.0,0....|   13|1.7827949628352202|\n",
      "|[-2.0,0.0,-1.0,0....|    0|0.9695770356522045|\n",
      "|[-2.0,0.0,0.0,-2....|    0|0.8341982945138846|\n",
      "+--------------------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------------------------------------------------------------------------------------+-----+------------------+\n",
      "|features                                                                                |label|prediction        |\n",
      "+----------------------------------------------------------------------------------------+-----+------------------+\n",
      "|[-2.0,-2.0,-1.0,0.0,0.0,-1.0,-1.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]  |0    |0.5944522752894505|\n",
      "|[-2.0,0.0,-1.0,0.0,1.0,0.0,1.0,0.0,-1.0,0.0,0.0,0.0,1.0,0.0,-2.0,0.0,0.0,0.0,0.0,0.0]   |0    |0.9600192271717508|\n",
      "|[-1.0,-1.0,-1.0,1.0,0.0,0.0,-1.0,0.0,-1.0,0.0,0.0,0.0,0.0,-1.0,0.0,0.0,0.0,0.0,0.0,0.0] |1    |0.9045493881876485|\n",
      "|[-1.0,-1.0,0.0,0.0,-1.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0]    |0    |1.109283842340457 |\n",
      "|[-1.0,-1.0,0.0,0.0,0.0,0.0,-1.0,1.0,0.0,1.0,0.0,-2.0,0.0,-1.0,0.0,0.0,0.0,0.0,-1.0,-1.0]|1    |0.8391872075170592|\n",
      "+----------------------------------------------------------------------------------------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "pred_training_cv = cv_model.transform(training)\n",
    "pred_test_cv = cv_model.transform(test)\n",
    "\n",
    "pred_training_cv.show(5)\n",
    "pred_test_cv.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-0.0102, -0.0148, -0.0065, 0.0121, 0.0549, 0.3, 0.0034, -0.0138, -0.008, -0.0112, 0.0086, -0.0054, -0.0144, -0.0007, -0.0127, -0.0006, -0.0143, 0.0153, 0.009, 0.0156])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.bestModel.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8557578945800948"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.bestModel.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7321924203471343"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(pred_training_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.713823529411765"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(pred_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
