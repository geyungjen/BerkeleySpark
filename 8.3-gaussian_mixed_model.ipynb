{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db818c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/18 17:19:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/05/18 17:19:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark K-means example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28f57902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import GaussianMixture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5013f7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format('csv').\\\n",
    "                       options(header='true', \\\n",
    "                       inferschema='true').\\\n",
    "            load(\"data/iris.csv\",header=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28402be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- sepal_length: double (nullable = true)\n",
      " |-- sepal_width: double (nullable = true)\n",
      " |-- petal_length: double (nullable = true)\n",
      " |-- petal_width: double (nullable = true)\n",
      " |-- species: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5,True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f4478a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+------------------+------------------+---------+\n",
      "|summary|      sepal_length|        sepal_width|      petal_length|       petal_width|  species|\n",
      "+-------+------------------+-------------------+------------------+------------------+---------+\n",
      "|  count|               150|                150|               150|               150|      150|\n",
      "|   mean| 5.843333333333335| 3.0540000000000007|3.7586666666666693|1.1986666666666672|     null|\n",
      "| stddev|0.8280661279778637|0.43359431136217375| 1.764420419952262|0.7631607417008414|     null|\n",
      "|    min|               4.3|                2.0|               1.0|               0.1|   setosa|\n",
      "|    max|               7.9|                4.4|               6.9|               2.5|virginica|\n",
      "+-------+------------------+-------------------+------------------+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d13f682",
   "metadata": {},
   "source": [
    "### We do not care the target label, as this is clustering, we are supposed to generate label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1c903df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|         features|\n",
      "+-----------------+\n",
      "|[5.1,3.5,1.4,0.2]|\n",
      "|[4.9,3.0,1.4,0.2]|\n",
      "|[4.7,3.2,1.3,0.2]|\n",
      "|[4.6,3.1,1.5,0.2]|\n",
      "|[5.0,3.6,1.4,0.2]|\n",
      "+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 7:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "transformed=df.rdd.map(lambda r: [Vectors.dense(r[:-1]),r[-1]]).toDF(['features','label']).select(\"features\")\n",
    "transformed.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbdc9dd",
   "metadata": {},
   "source": [
    "Deal With Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89e30dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|         features|  indexedFeatures|\n",
      "+-----------------+-----------------+\n",
      "|[5.1,3.5,1.4,0.2]|[5.1,3.5,1.4,0.2]|\n",
      "|[4.9,3.0,1.4,0.2]|[4.9,3.0,1.4,0.2]|\n",
      "|[4.7,3.2,1.3,0.2]|[4.7,3.2,1.3,0.2]|\n",
      "|[4.6,3.1,1.5,0.2]|[4.6,3.1,1.5,0.2]|\n",
      "|[5.0,3.6,1.4,0.2]|[5.0,3.6,1.4,0.2]|\n",
      "+-----------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", \\\n",
    "                               outputCol=\"indexedFeatures\",\\\n",
    "                               maxCategories=4).fit(transformed)\n",
    "\n",
    "data = featureIndexer.transform(transformed)\n",
    "data.show(5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "169de968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|         features|\n",
      "+-----------------+\n",
      "|[5.1,3.5,1.4,0.2]|\n",
      "|[4.9,3.0,1.4,0.2]|\n",
      "|[4.7,3.2,1.3,0.2]|\n",
      "|[4.6,3.1,1.5,0.2]|\n",
      "|[5.0,3.6,1.4,0.2]|\n",
      "+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.createOrReplaceTempView(\"data\")\n",
    "data=spark.sql(\"select indexedFeatures as features from data\")\n",
    "data.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd895d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains Gaussian Mixture Model\n",
    "gmm = GaussianMixture(k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abb9787",
   "metadata": {},
   "source": [
    "### clustering algorithm is for unsupervised learning, therefore, no training and testing splits necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f63c5ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 12:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/18 17:19:36 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "23/05/18 17:19:36 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n",
      "23/05/18 17:19:36 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "23/05/18 17:19:36 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "23/05/18 17:19:36 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/05/18 17:19:36 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 14:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Chain indexer and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[gmm])\n",
    "model = pipeline.fit(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ec331fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61feefb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------------------------------------------------------+----------+\n",
      "|features         |probability                                                      |prediction|\n",
      "+-----------------+-----------------------------------------------------------------+----------+\n",
      "|[5.1,3.5,1.4,0.2]|[4.734799396261589E-17,0.9999999997849096,2.1509033078181288E-10]|1         |\n",
      "|[4.9,3.0,1.4,0.2]|[8.242255300723322E-15,0.9999997487664355,2.5123355615813866E-7] |1         |\n",
      "|[4.7,3.2,1.3,0.2]|[3.704702543514495E-16,0.9999999338662796,6.613371996012292E-8]  |1         |\n",
      "|[4.6,3.1,1.5,0.2]|[1.7264949151793987E-13,0.9999998802939727,1.197058546285927E-7] |1         |\n",
      "|[5.0,3.6,1.4,0.2]|[5.785073474861345E-17,0.9999999999088787,9.112123028276783E-11] |1         |\n",
      "|[5.4,3.9,1.7,0.4]|[2.437845167521415E-16,0.9999999997220376,2.779621827766594E-10] |1         |\n",
      "|[4.6,3.4,1.4,0.3]|[5.079352293083531E-16,0.9999998192072068,1.8079279267312214E-7] |1         |\n",
      "|[5.0,3.4,1.5,0.2]|[1.2164666770872424E-16,0.9999999991358027,8.641971854361422E-10]|1         |\n",
      "|[4.4,2.9,1.4,0.2]|[9.994198855091648E-13,0.9999966484936971,3.351505303394262E-6]  |1         |\n",
      "|[4.9,3.1,1.5,0.1]|[6.639293705663515E-14,0.999999997140782,2.8591516196178767E-9]  |1         |\n",
      "|[5.4,3.7,1.5,0.2]|[9.461638010436034E-17,0.9999999999955789,4.421071508042284E-12] |1         |\n",
      "|[4.8,3.4,1.6,0.2]|[4.787284418459278E-15,0.9999999987253577,1.2746374284527512E-9] |1         |\n",
      "|[4.8,3.0,1.4,0.1]|[4.714589248504756E-14,0.9999999813905751,1.860937771273721E-8]  |1         |\n",
      "|[4.3,3.0,1.1,0.1]|[1.825384300032522E-14,0.9999982721860379,1.7278139438142232E-6] |1         |\n",
      "|[5.8,4.0,1.2,0.2]|[6.904145898205856E-15,0.99999999999996,3.29668243497453E-14]    |1         |\n",
      "|[5.7,4.4,1.5,0.4]|[1.6831007150020518E-15,0.9999999999999711,2.710995339577729E-14]|1         |\n",
      "|[5.4,3.9,1.3,0.4]|[6.211761366388445E-16,0.999999999923818,7.618140633324088E-11]  |1         |\n",
      "|[5.1,3.5,1.4,0.3]|[5.215241672612785E-17,0.9999999963719356,3.628064474675092E-9]  |1         |\n",
      "|[5.7,3.8,1.7,0.3]|[5.073246756953257E-16,0.9999999999804735,1.952595102879117E-11] |1         |\n",
      "|[5.1,3.8,1.5,0.3]|[8.656432185913532E-17,0.9999999999110092,8.899054821941973E-11] |1         |\n",
      "+-----------------+-----------------------------------------------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cluster.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe8b736b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3679542368270777, [6.222739873722937,2.9544088011137513,5.078348688349975,1.858811639230237], DenseMatrix([[0.27354254, 0.06839109, 0.22347098, 0.12722684],\n",
      "             [0.06839109, 0.06450981, 0.06277417, 0.05153339],\n",
      "             [0.22347098, 0.06277417, 0.31957783, 0.18490413],\n",
      "             [0.12722684, 0.05153339, 0.18490413, 0.1583885 ]])\n",
      "0.3331255382005878, [5.006313815873003,3.4186934435434684,1.4641011574974798,0.243964220238869], DenseMatrix([[0.12168099, 0.09800223, 0.01577433, 0.01036   ],\n",
      "             [0.09800223, 0.14158903, 0.01134136, 0.01125382],\n",
      "             [0.01577433, 0.01134136, 0.0295056 , 0.005593  ],\n",
      "             [0.01036   , 0.01125382, 0.005593  , 0.01126874]])\n",
      "0.2989202249723345, [6.309104203253557,2.770166090515914,4.691342865011557,1.450013415518377], DenseMatrix([[0.63138072, 0.19500516, 0.74876637, 0.23363146],\n",
      "             [0.19500516, 0.14656056, 0.20009054, 0.07224747],\n",
      "             [0.74876637, 0.20009054, 1.03789818, 0.32604766],\n",
      "             [0.23363146, 0.07224747, 0.32604766, 0.11251423]])\n"
     ]
    }
   ],
   "source": [
    "gaussianM=model.stages[0]\n",
    "for i in range(gaussianM.getK()):\n",
    "    print(f\"{gaussianM.weights[i]}, {gaussianM.gaussians[i].mean}, {gaussianM.gaussians[i].cov}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9ad4af",
   "metadata": {},
   "source": [
    "https://stats.stackexchange.com/questions/192168/is-the-covariance-matrix-the-equivalent-of-standard-deviation-for-a-2d-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b7a06d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
