{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/25 16:44:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(conf=SparkConf())\n",
    "spark = SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression with pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('data/SparkData/bank.csv', header=True, inferSchema=True, sep=\";\")\n",
    "#df.drop('day','month','poutcome').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "|age|        job|marital|education|default|balance|housing|loan| contact|day|month|duration|campaign|pdays|previous|poutcome|  y|\n",
      "+---+-----------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "| 30| unemployed|married|  primary|     no|   1787|     no|  no|cellular| 19|  oct|      79|       1|   -1|       0| unknown| no|\n",
      "| 33|   services|married|secondary|     no|   4789|    yes| yes|cellular| 11|  may|     220|       1|  339|       4| failure| no|\n",
      "| 35| management| single| tertiary|     no|   1350|    yes|  no|cellular| 16|  apr|     185|       1|  330|       1| failure| no|\n",
      "| 30| management|married| tertiary|     no|   1476|    yes| yes| unknown|  3|  jun|     199|       4|   -1|       0| unknown| no|\n",
      "| 59|blue-collar|married|secondary|     no|      0|    yes|  no| unknown|  5|  may|     226|       1|   -1|       0| unknown| no|\n",
      "+---+-----------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- balance: integer (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply abs() to all numeric columns as Naive Bayes does not allow negative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"dfView\")\n",
    "df=spark.sql(\"select job,marital,education,default,housing,loan,contact,poutcome,\\\n",
    "  abs(balance) balance, abs(duration) duration, abs(campaign) campaign,\\\n",
    "  abs(pdays) pdays,abs(previous) previous, y from dfView\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Deal with categorical data and Convert the data to  vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcols = ['job','marital','education','default','housing','loan','contact','poutcome']\n",
    "num_cols = ['balance', 'duration','campaign','pdays','previous']\n",
    "labelCol = 'y'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code does three things with pipeline:\n",
    "\n",
    "* **`StringIndexer`** all categorical columns\n",
    "* **`OneHotEncoder`** all categorical index columns\n",
    "* **`VectorAssembler`** all feature columns into one vector column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, Normalizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# categorical columns\n",
    "categorical_columns = catcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexers = [ StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c)) for c in categorical_columns ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(), \\\n",
    "                           outputCol=\"{0}_encoded\".format(indexer.getOutputCol())) for indexer in indexers ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[encoder.getOutputCol() \\\n",
    "                                       for encoder in encoders] + num_cols, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/25 16:44:58 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "+---------------------------------------------------------------------------------------------------------+-----+\n",
      "|features                                                                                                 |label|\n",
      "+---------------------------------------------------------------------------------------------------------+-----+\n",
      "|(29,[8,11,15,16,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1787.0,79.0,1.0,1.0])                 |no   |\n",
      "|(29,[4,11,13,16,17,19,22,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,4789.0,220.0,1.0,339.0,4.0])       |no   |\n",
      "|(29,[0,12,14,16,17,18,19,22,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1350.0,185.0,1.0,330.0,1.0])|no   |\n",
      "|(29,[0,11,14,16,17,20,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1476.0,199.0,4.0,1.0])                |no   |\n",
      "|(29,[1,11,13,16,17,18,20,21,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,226.0,1.0,1.0])                   |no   |\n",
      "+---------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
    "model=pipeline.fit(df)\n",
    "data = model.transform(df)\n",
    "data = data.withColumn('label',col(labelCol))\n",
    "data=data.select('features','label')\n",
    "data.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need normalize all features to make the value range of each feature similar scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer(inputCol=\"features\",outputCol=\"normFeatures\",p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=normalizer.transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                                 |label|normFeatures                                                                                                                                                                                                                                                                                                |\n",
      "+---------------------------------------------------------------------------------------------------------+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(29,[8,11,15,16,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1787.0,79.0,1.0,1.0])                 |no   |(29,[8,11,15,16,18,19,21,24,25,26,27],[5.333333333333334E-4,5.333333333333334E-4,5.333333333333334E-4,5.333333333333334E-4,5.333333333333334E-4,5.333333333333334E-4,5.333333333333334E-4,0.9530666666666666,0.042133333333333335,5.333333333333334E-4,5.333333333333334E-4])                               |\n",
      "|(29,[4,11,13,16,17,19,22,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,4789.0,220.0,1.0,339.0,4.0])       |no   |(29,[4,11,13,16,17,19,22,24,25,26,27,28],[1.8656716417910448E-4,1.8656716417910448E-4,1.8656716417910448E-4,1.8656716417910448E-4,1.8656716417910448E-4,1.8656716417910448E-4,1.8656716417910448E-4,0.8934701492537314,0.041044776119402986,1.8656716417910448E-4,0.06324626865671641,7.462686567164179E-4])|\n",
      "|(29,[0,12,14,16,17,18,19,22,24,25,26,27,28],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1350.0,185.0,1.0,330.0,1.0])|no   |(29,[0,12,14,16,17,18,19,22,24,25,26,27,28],[5.333333333333334E-4,5.333333333333334E-4,5.333333333333334E-4,5.333333333333334E-4,5.333333333333334E-4,5.333333333333334E-4,5.333333333333334E-4,5.333333333333334E-4,0.72,0.09866666666666667,5.333333333333334E-4,0.176,5.333333333333334E-4])             |\n",
      "|(29,[0,11,14,16,17,20,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1476.0,199.0,4.0,1.0])                |no   |(29,[0,11,14,16,17,20,21,24,25,26,27],[5.927682276229994E-4,5.927682276229994E-4,5.927682276229994E-4,5.927682276229994E-4,5.927682276229994E-4,5.927682276229994E-4,5.927682276229994E-4,0.8749259039715471,0.11796087729697688,0.0023710729104919974,5.927682276229994E-4])                               |\n",
      "|(29,[1,11,13,16,17,18,20,21,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,226.0,1.0,1.0])                   |no   |(29,[1,11,13,16,17,18,20,21,25,26,27],[0.00423728813559322,0.00423728813559322,0.00423728813559322,0.00423728813559322,0.00423728813559322,0.00423728813559322,0.00423728813559322,0.00423728813559322,0.9576271186440678,0.00423728813559322,0.00423728813559322])                                         |\n",
      "+---------------------------------------------------------------------------------------------------------+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5, False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to deal with label, which is string, yes or no, need to make them numbers\n",
    "### Build StringIndexer stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index labels, adding metadata to the label column \n",
    "labelIndexer = StringIndexer(inputCol='label',\n",
    "                             outputCol='indexedLabel').fit(data)\n",
    "data=labelIndexer.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+------------+\n",
      "|            features|label|        normFeatures|indexedLabel|\n",
      "+--------------------+-----+--------------------+------------+\n",
      "|(29,[8,11,15,16,1...|   no|(29,[8,11,15,16,1...|         0.0|\n",
      "|(29,[4,11,13,16,1...|   no|(29,[4,11,13,16,1...|         0.0|\n",
      "|(29,[0,12,14,16,1...|   no|(29,[0,12,14,16,1...|         0.0|\n",
      "|(29,[0,11,14,16,1...|   no|(29,[0,11,14,16,1...|         0.0|\n",
      "|(29,[1,11,13,16,1...|   no|(29,[1,11,13,16,1...|         0.0|\n",
      "+--------------------+-----+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorIndexer\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous. \n",
    "# Update metadata accordingly.\n",
    "featureIndexer =VectorIndexer(inputCol=\"normFeatures\", \\\n",
    "                                  outputCol=\"indexedFeatures\", \\\n",
    "                                  maxCategories=4).fit(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+------------+--------------------+\n",
      "|            features|label|        normFeatures|indexedLabel|     indexedFeatures|\n",
      "+--------------------+-----+--------------------+------------+--------------------+\n",
      "|(29,[8,11,15,16,1...|   no|(29,[8,11,15,16,1...|         0.0|(29,[8,11,15,16,1...|\n",
      "|(29,[4,11,13,16,1...|   no|(29,[4,11,13,16,1...|         0.0|(29,[4,11,13,16,1...|\n",
      "|(29,[0,12,14,16,1...|   no|(29,[0,12,14,16,1...|         0.0|(29,[0,12,14,16,1...|\n",
      "|(29,[0,11,14,16,1...|   no|(29,[0,11,14,16,1...|         0.0|(29,[0,11,14,16,1...|\n",
      "|(29,[1,11,13,16,1...|   no|(29,[1,11,13,16,1...|         0.0|(29,[1,11,13,16,1...|\n",
      "+--------------------+-----+--------------------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=featureIndexer.transform(data)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data to training and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------+-----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                       |label|normFeatures                                                                                                                                                                                                                                                                                                 |indexedLabel|indexedFeatures                                                                                                                                                                                                                                                                                              |\n",
      "+-----------------------------------------------------------------------------------------------+-----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,11.0,104.0,3.0,1.0]) |no   |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[0.007874015748031496,0.007874015748031496,0.007874015748031496,0.007874015748031496,0.007874015748031496,0.007874015748031496,0.007874015748031496,0.007874015748031496,0.08661417322834646,0.8188976377952756,0.023622047244094488,0.007874015748031496])         |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[0.007874015748031496,0.007874015748031496,0.007874015748031496,0.007874015748031496,0.007874015748031496,0.007874015748031496,0.007874015748031496,0.007874015748031496,0.08661417322834646,0.8188976377952756,0.023622047244094488,0.007874015748031496])         |\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,238.0,808.0,1.0,1.0])|no   |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[9.46969696969697E-4,9.46969696969697E-4,9.46969696969697E-4,9.46969696969697E-4,9.46969696969697E-4,9.46969696969697E-4,9.46969696969697E-4,9.46969696969697E-4,0.22537878787878787,0.7651515151515151,9.46969696969697E-4,9.46969696969697E-4])                   |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[9.46969696969697E-4,9.46969696969697E-4,9.46969696969697E-4,9.46969696969697E-4,9.46969696969697E-4,9.46969696969697E-4,9.46969696969697E-4,9.46969696969697E-4,0.22537878787878787,0.7651515151515151,9.46969696969697E-4,9.46969696969697E-4])                   |\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,407.0,145.0,2.0,1.0])|no   |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[0.0017761989342806395,0.0017761989342806395,0.0017761989342806395,0.0017761989342806395,0.0017761989342806395,0.0017761989342806395,0.0017761989342806395,0.0017761989342806395,0.7229129662522202,0.25754884547069273,0.003552397868561279,0.0017761989342806395])|0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[0.0017761989342806395,0.0017761989342806395,0.0017761989342806395,0.0017761989342806395,0.0017761989342806395,0.0017761989342806395,0.0017761989342806395,0.0017761989342806395,0.7229129662522202,0.25754884547069273,0.003552397868561279,0.0017761989342806395])|\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,466.0,164.0,1.0,1.0])|no   |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[0.0015625,0.0015625,0.0015625,0.0015625,0.0015625,0.0015625,0.0015625,0.0015625,0.728125,0.25625,0.0015625,0.0015625])                                                                                                                                             |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[0.0015625,0.0015625,0.0015625,0.0015625,0.0015625,0.0015625,0.0015625,0.0015625,0.728125,0.25625,0.0015625,0.0015625])                                                                                                                                             |\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,588.0,81.0,4.0,1.0]) |no   |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[0.001466275659824047,0.001466275659824047,0.001466275659824047,0.001466275659824047,0.001466275659824047,0.001466275659824047,0.001466275659824047,0.001466275659824047,0.8621700879765396,0.1187683284457478,0.005865102639296188,0.001466275659824047])          |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[0.001466275659824047,0.001466275659824047,0.001466275659824047,0.001466275659824047,0.001466275659824047,0.001466275659824047,0.001466275659824047,0.001466275659824047,0.8621700879765396,0.1187683284457478,0.005865102639296188,0.001466275659824047])          |\n",
      "+-----------------------------------------------------------------------------------------------+-----+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------------------------------------------------------------------------------------------------+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                        |label|normFeatures                                                                                                                                                                                                                                                                                                  |indexedLabel|indexedFeatures                                                                                                                                                                                                                                                                                               |\n",
      "+------------------------------------------------------------------------------------------------+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,105.0,60.0,2.0,1.0])  |no   |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[0.005681818181818182,0.005681818181818182,0.005681818181818182,0.005681818181818182,0.005681818181818182,0.005681818181818182,0.005681818181818182,0.005681818181818182,0.5965909090909091,0.3409090909090909,0.011363636363636364,0.005681818181818182])           |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[0.005681818181818182,0.005681818181818182,0.005681818181818182,0.005681818181818182,0.005681818181818182,0.005681818181818182,0.005681818181818182,0.005681818181818182,0.5965909090909091,0.3409090909090909,0.011363636363636364,0.005681818181818182])           |\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,117.0,635.0,1.0,1.0]) |no   |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[0.0013123359580052493,0.0013123359580052493,0.0013123359580052493,0.0013123359580052493,0.0013123359580052493,0.0013123359580052493,0.0013123359580052493,0.0013123359580052493,0.15354330708661418,0.8333333333333334,0.0013123359580052493,0.0013123359580052493])|0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[0.0013123359580052493,0.0013123359580052493,0.0013123359580052493,0.0013123359580052493,0.0013123359580052493,0.0013123359580052493,0.0013123359580052493,0.0013123359580052493,0.15354330708661418,0.8333333333333334,0.0013123359580052493,0.0013123359580052493])|\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,857.0,238.0,6.0,1.0]) |no   |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[9.009009009009009E-4,9.009009009009009E-4,9.009009009009009E-4,9.009009009009009E-4,9.009009009009009E-4,9.009009009009009E-4,9.009009009009009E-4,9.009009009009009E-4,0.7720720720720721,0.21441441441441442,0.005405405405405406,9.009009009009009E-4])          |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[9.009009009009009E-4,9.009009009009009E-4,9.009009009009009E-4,9.009009009009009E-4,9.009009009009009E-4,9.009009009009009E-4,9.009009009009009E-4,9.009009009009009E-4,0.7720720720720721,0.21441441441441442,0.005405405405405406,9.009009009009009E-4])          |\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1007.0,240.0,2.0,1.0])|no   |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[7.94912559618442E-4,7.94912559618442E-4,7.94912559618442E-4,7.94912559618442E-4,7.94912559618442E-4,7.94912559618442E-4,7.94912559618442E-4,7.94912559618442E-4,0.800476947535771,0.1907790143084261,0.001589825119236884,7.94912559618442E-4])                     |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[7.94912559618442E-4,7.94912559618442E-4,7.94912559618442E-4,7.94912559618442E-4,7.94912559618442E-4,7.94912559618442E-4,7.94912559618442E-4,7.94912559618442E-4,0.800476947535771,0.1907790143084261,0.001589825119236884,7.94912559618442E-4])                     |\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,3180.0,384.0,1.0,1.0])|no   |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[2.797985450475658E-4,2.797985450475658E-4,2.797985450475658E-4,2.797985450475658E-4,2.797985450475658E-4,2.797985450475658E-4,2.797985450475658E-4,2.797985450475658E-4,0.8897593732512591,0.10744264129826525,2.797985450475658E-4,2.797985450475658E-4])          |0.0         |(29,[0,11,13,16,17,18,19,21,24,25,26,27],[2.797985450475658E-4,2.797985450475658E-4,2.797985450475658E-4,2.797985450475658E-4,2.797985450475658E-4,2.797985450475658E-4,2.797985450475658E-4,2.797985450475658E-4,0.8897593732512591,0.10744264129826525,2.797985450475658E-4,2.797985450475658E-4])          |\n",
      "+------------------------------------------------------------------------------------------------+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets (40% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.6, 0.4])\n",
    "trainingData.show(5,False)\n",
    "testData.show(5,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build cross-validation model\n",
    "\n",
    "\n",
    "### Cross-Validation\n",
    "\n",
    "In general, one round of cross-validation involves partitioning a sample of data into complementary subsets, performing the analysis on one subset (called the training set), and validating the analysis on the other subset (called the validation set or testing set).\n",
    "CrossValidator begins by splitting the dataset into a set of folds which are used as separate training and test datasets. E.g., with k=3 folds, CrossValidator will generate 3 (training, test) dataset pairs, each of which uses 2/3 of the data for training and 1/3 for testing. To evaluate a particular ParamMap, CrossValidator computes the average evaluation metric for the 3 Models produced by fitting the Estimator on the 3 different (training, test) dataset pairs.\n",
    "\n",
    "After identifying the best ParamMap, CrossValidator finally re-fits the Estimator using the best ParamMap and the entire dataset.  In simple term, pickup the ParamMap that produces the best model and to use that model for subsequent transform().\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "naivebayes = NaiveBayes(featuresCol=\"normFeatures\", labelCol=\"indexedLabel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert indexed labels back to original labels.\n",
    "from pyspark.ml.feature import IndexToString\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[naivebayes,labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------+--------------------+\n",
      "|            features|label|predictedLabel|       rawPrediction|\n",
      "+--------------------+-----+--------------+--------------------+\n",
      "|(29,[0,11,13,16,1...|   no|            no|[-1.1737243598968...|\n",
      "|(29,[0,11,13,16,1...|   no|            no|[-1.1874075823042...|\n",
      "|(29,[0,11,13,16,1...|   no|            no|[-0.8444796851804...|\n",
      "|(29,[0,11,13,16,1...|   no|            no|[-0.8101712555432...|\n",
      "|(29,[0,11,13,16,1...|   no|            no|[-0.7335767665447...|\n",
      "+--------------------+-----+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "# Select example rows to display. \n",
    "predictions.select(\"features\",\"label\",\"predictedLabel\", \"rawPrediction\").show(5)\n",
    "#predictions.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "### BinaryClassificationEvaluator only provide accuracy metrics, you need MulticlassClassificationEvaluator to provide all metrics, MulticlassClassificationEvaluator work with binary classification too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.887213847012842\n",
      "Test Error = 0.112786\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy = {accuracy}\")\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate training model\n",
    "\n",
    "area under ROC  https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc\n",
    "\n",
    "accuracy\n",
    "\n",
    "False positive rate by label\n",
    "\n",
    "True positive rate by label\n",
    "\n",
    "Precision by label\n",
    "\n",
    "Recall by label\n",
    "\n",
    "F-measure by label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data (f1): 0.8341910076351514 \n",
      " training data (weightedPrecision):  0.7871484103313267 \n",
      " training data (weightedRecall):  0.887213847012842 \n",
      " training data (accuracy):  0.887213847012842\n"
     ]
    }
   ],
   "source": [
    "print('training data (f1):', evaluator.setMetricName('f1').evaluate(predictions), \"\\n\",\n",
    "     'training data (weightedPrecision): ', evaluator.setMetricName('weightedPrecision').evaluate(predictions),\"\\n\",\n",
    "     'training data (weightedRecall): ', evaluator.setMetricName('weightedRecall').evaluate(predictions),\"\\n\",\n",
    "     'training data (accuracy): ', evaluator.setMetricName('accuracy').evaluate(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
