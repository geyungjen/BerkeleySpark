{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8554cc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/03 11:48:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark regression example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48181b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format('csv').\\\n",
    "                       options(header='true', \\\n",
    "                       inferschema='true').\\\n",
    "            load(\"data/Advertising.csv\",header=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59918a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---------+-----+\n",
      "|   TV|Radio|Newspaper|Sales|\n",
      "+-----+-----+---------+-----+\n",
      "|230.1| 37.8|     69.2| 22.1|\n",
      "| 44.5| 39.3|     45.1| 10.4|\n",
      "| 17.2| 45.9|     69.3|  9.3|\n",
      "|151.5| 41.3|     58.5| 18.5|\n",
      "|180.8| 10.8|     58.4| 12.9|\n",
      "+-----+-----+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- TV: double (nullable = true)\n",
      " |-- Radio: double (nullable = true)\n",
      " |-- Newspaper: double (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5,True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac61cb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|summary|               TV|             Radio|         Newspaper|             Sales|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|  count|              200|               200|               200|               200|\n",
      "|   mean|         147.0425|23.264000000000024|30.553999999999995|14.022500000000003|\n",
      "| stddev|85.85423631490805|14.846809176168728| 21.77862083852283| 5.217456565710477|\n",
      "|    min|              0.7|               0.0|               0.3|               1.6|\n",
      "|    max|            296.4|              49.6|             114.0|              27.0|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481e027f",
   "metadata": {},
   "source": [
    "## Convert the data to dense vector (features and label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18d14fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|label|         features|\n",
      "+-----+-----------------+\n",
      "| 22.1|[230.1,37.8,69.2]|\n",
      "| 10.4| [44.5,39.3,45.1]|\n",
      "|  9.3| [17.2,45.9,69.3]|\n",
      "| 18.5|[151.5,41.3,58.5]|\n",
      "| 12.9|[180.8,10.8,58.4]|\n",
      "+-----+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 7:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "transformed = df.rdd.map(lambda r: [r[-1], Vectors.dense(r[:-1])]).toDF(['label','features'])\n",
    "transformed.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d72813",
   "metadata": {},
   "source": [
    "You will find out that all of the machine learning algorithms in Spark are based on the features and label. That is to say, you can play with all of the machine learning algorithms in Spark when you get ready the features and label.\n",
    "\n",
    "Deal with categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2a9c8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4\n",
    "# distinct values are treated as continuous.\n",
    "\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", \\\n",
    "                               outputCol=\"indexedFeatures\",\\\n",
    "                               maxCategories=4).fit(transformed)\n",
    "\n",
    "data = featureIndexer.transform(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ab51f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+-----------------+\n",
      "|label|         features|  indexedFeatures|\n",
      "+-----+-----------------+-----------------+\n",
      "| 22.1|[230.1,37.8,69.2]|[230.1,37.8,69.2]|\n",
      "| 10.4| [44.5,39.3,45.1]| [44.5,39.3,45.1]|\n",
      "|  9.3| [17.2,45.9,69.3]| [17.2,45.9,69.3]|\n",
      "| 18.5|[151.5,41.3,58.5]|[151.5,41.3,58.5]|\n",
      "| 12.9|[180.8,10.8,58.4]|[180.8,10.8,58.4]|\n",
      "+-----+-----------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0c6f66",
   "metadata": {},
   "source": [
    "Fit Decision Tree Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb5d34a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeRegressor(featuresCol=\"indexedFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "038cceda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 11:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------+----------------+\n",
      "|label|        features| indexedFeatures|\n",
      "+-----+----------------+----------------+\n",
      "|  1.6|  [0.7,39.6,8.7]|  [0.7,39.6,8.7]|\n",
      "|  4.8|   [8.6,2.1,1.0]|   [8.6,2.1,1.0]|\n",
      "|  5.3|  [5.4,29.9,9.4]|  [5.4,29.9,9.4]|\n",
      "|  5.5| [7.3,28.1,41.4]| [7.3,28.1,41.4]|\n",
      "|  5.6|[13.2,15.9,49.6]|[13.2,15.9,49.6]|\n",
      "+-----+----------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# split data into training and test datasets\n",
    "trainingData, testData = data.randomSplit([0.8, 0.2], seed=1234)\n",
    "trainingData.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d7e5b6",
   "metadata": {},
   "source": [
    "Pipeline Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f363354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain indexer and decision tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, dt])\n",
    "\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfb93e9",
   "metadata": {},
   "source": [
    "Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f93fdf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4148ef97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------+----------------+-----------------+\n",
      "|label|        features| indexedFeatures|       prediction|\n",
      "+-----+----------------+----------------+-----------------+\n",
      "|  3.2|  [4.1,11.6,5.7]|  [4.1,11.6,5.7]|              5.7|\n",
      "|  5.3| [13.1,0.4,25.6]| [13.1,0.4,25.6]|5.466666666666666|\n",
      "|  8.1| [53.5,2.0,21.4]| [53.5,2.0,21.4]|              8.4|\n",
      "|  8.6| [66.1,5.8,24.2]| [66.1,5.8,24.2]|             10.1|\n",
      "|  8.7|[16.9,43.7,89.4]|[16.9,43.7,89.4]|             8.96|\n",
      "+-----+----------------+----------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 46:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d7de24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+-----------------+\n",
      "|        features|label|       prediction|\n",
      "+----------------+-----+-----------------+\n",
      "|  [4.1,11.6,5.7]|  3.2|              5.7|\n",
      "| [13.1,0.4,25.6]|  5.3|5.466666666666666|\n",
      "| [53.5,2.0,21.4]|  8.1|              8.4|\n",
      "| [66.1,5.8,24.2]|  8.6|             10.1|\n",
      "|[16.9,43.7,89.4]|  8.7|             8.96|\n",
      "+----------------+-----+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select example rows to display.\n",
    "predictions.select(\"features\",\"label\",\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef6174d",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfd413e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 1.24168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 48:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\",\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"rmse\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9210de78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.9454161819062926\n"
     ]
    }
   ],
   "source": [
    "y_true = predictions.select(\"label\").toPandas()\n",
    "y_pred = predictions.select(\"prediction\").toPandas()\n",
    "\n",
    "import sklearn.metrics\n",
    "r2_score = sklearn.metrics.r2_score(y_true, y_pred)\n",
    "print('r2_score: {0}'.format(r2_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb16f5fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
