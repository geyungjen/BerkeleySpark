{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f086e47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/08 00:01:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/05/08 00:02:00 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/05/08 00:02:00 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark GBTRegressor example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d0c021e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---------+-----+\n",
      "|   TV|Radio|Newspaper|Sales|\n",
      "+-----+-----+---------+-----+\n",
      "|230.1| 37.8|     69.2| 22.1|\n",
      "| 44.5| 39.3|     45.1| 10.4|\n",
      "| 17.2| 45.9|     69.3|  9.3|\n",
      "|151.5| 41.3|     58.5| 18.5|\n",
      "|180.8| 10.8|     58.4| 12.9|\n",
      "+-----+-----+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- TV: double (nullable = true)\n",
      " |-- Radio: double (nullable = true)\n",
      " |-- Newspaper: double (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('com.databricks.spark.csv').\\\n",
    "                               options(header='true', \\\n",
    "                               inferschema='true').\\\n",
    "                               load(\"data/Advertising.csv\",header=True);\n",
    "\n",
    "df.show(5,True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e63d7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|summary|               TV|             Radio|         Newspaper|             Sales|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|  count|              200|               200|               200|               200|\n",
      "|   mean|         147.0425|23.264000000000024|30.553999999999995|14.022500000000003|\n",
      "| stddev|85.85423631490805|14.846809176168728| 21.77862083852283| 5.217456565710477|\n",
      "|    min|              0.7|               0.0|               0.3|               1.6|\n",
      "|    max|            296.4|              49.6|             114.0|              27.0|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b608b39",
   "metadata": {},
   "source": [
    "Convert the data to dense vector (features and label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef09260b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|         features|label|\n",
      "+-----------------+-----+\n",
      "|[230.1,37.8,69.2]| 22.1|\n",
      "| [44.5,39.3,45.1]| 10.4|\n",
      "| [17.2,45.9,69.3]|  9.3|\n",
      "|[151.5,41.3,58.5]| 18.5|\n",
      "|[180.8,10.8,58.4]| 12.9|\n",
      "+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 7:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "transformed=df.rdd.map(lambda r: [Vectors.dense(r[:-1]),r[-1]]).toDF(['features','label'])\n",
    "transformed.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9627ba3c",
   "metadata": {},
   "source": [
    "Deal with the Categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f19f3eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+-----------------+\n",
      "|         features|label|  indexedFeatures|\n",
      "+-----------------+-----+-----------------+\n",
      "|[230.1,37.8,69.2]| 22.1|[230.1,37.8,69.2]|\n",
      "| [44.5,39.3,45.1]| 10.4| [44.5,39.3,45.1]|\n",
      "| [17.2,45.9,69.3]|  9.3| [17.2,45.9,69.3]|\n",
      "|[151.5,41.3,58.5]| 18.5|[151.5,41.3,58.5]|\n",
      "|[180.8,10.8,58.4]| 12.9|[180.8,10.8,58.4]|\n",
      "+-----------------+-----+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", \\\n",
    "                               outputCol=\"indexedFeatures\",\\\n",
    "                               maxCategories=4).fit(transformed)\n",
    "\n",
    "data = featureIndexer.transform(transformed)\n",
    "data.show(5,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8b5836",
   "metadata": {},
   "source": [
    "Split the data into training and test sets (40% held out for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "682e0fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 11:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+---------------+\n",
      "|       features|label|indexedFeatures|\n",
      "+---------------+-----+---------------+\n",
      "| [0.7,39.6,8.7]|  1.6| [0.7,39.6,8.7]|\n",
      "| [4.1,11.6,5.7]|  3.2| [4.1,11.6,5.7]|\n",
      "|[7.8,38.9,50.6]|  6.6|[7.8,38.9,50.6]|\n",
      "|[8.7,48.9,75.0]|  7.2|[8.7,48.9,75.0]|\n",
      "|[13.1,0.4,25.6]|  5.3|[13.1,0.4,25.6]|\n",
      "+---------------+-----+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------------+-----+----------------+\n",
      "|        features|label| indexedFeatures|\n",
      "+----------------+-----+----------------+\n",
      "|  [5.4,29.9,9.4]|  5.3|  [5.4,29.9,9.4]|\n",
      "| [7.3,28.1,41.4]|  5.5| [7.3,28.1,41.4]|\n",
      "|  [8.4,27.2,2.1]|  5.7|  [8.4,27.2,2.1]|\n",
      "|   [8.6,2.1,1.0]|  4.8|   [8.6,2.1,1.0]|\n",
      "|[11.7,36.9,45.2]|  7.3|[11.7,36.9,45.2]|\n",
      "+----------------+-----+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets (40% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.6, 0.4])\n",
    "\n",
    "trainingData.show(5)\n",
    "testData.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb76071",
   "metadata": {},
   "source": [
    "Fit IsotonicRegression Regression Model with IsotonicRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "867271aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import IsotonicRegression class\n",
    "from pyspark.ml.regression import IsotonicRegression\n",
    "\n",
    "# Define LinearRegression algorithm\n",
    "iso = IsotonicRegression(featuresCol=\"indexedFeatures\", labelCol=\"label\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defeee59",
   "metadata": {},
   "source": [
    "If you decide to use the indexedFeatures features, you need to add the parameter featuresCol=\"indexedFeatures\".\n",
    "\n",
    "Pipeline Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ded60d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Chain indexer and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, iso])\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12829ddb",
   "metadata": {},
   "source": [
    "Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46b2cf24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+-----------------+\n",
      "|        features|label|       prediction|\n",
      "+----------------+-----+-----------------+\n",
      "|  [5.4,29.9,9.4]|  5.3|4.271621621621622|\n",
      "| [7.3,28.1,41.4]|  5.5|5.837837837837838|\n",
      "|  [8.4,27.2,2.1]|  5.7|             6.25|\n",
      "|   [8.6,2.1,1.0]|  4.8|             6.25|\n",
      "|[11.7,36.9,45.2]|  7.3|             6.25|\n",
      "+----------------+-----+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"features\",\"label\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8412fb",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93e752db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 3.23095\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a893d1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data = 0.576691\n",
      "23/05/08 09:09:58 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 7197419 ms exceeds timeout 120000 ms\n",
      "23/05/08 09:09:58 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"label\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d151c87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
